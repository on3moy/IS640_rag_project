{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Verification Notebook\n",
    "\n",
    "Run all cells in this notebook to verify your environment is set up correctly.\n",
    "\n",
    "## What This Tests:\n",
    "1. Python dependencies\n",
    "2. Ollama LLM connection\n",
    "3. Embedding model\n",
    "4. ChromaDB vector database\n",
    "5. Basic LLM interaction\n",
    "\n",
    "If all cells run successfully, you're ready to start the project!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.9 | packaged by conda-forge | (main, Oct 22 2025, 23:12:41) [MSC v.1944 64 bit (AMD64)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ChromaDB imported successfully\n",
      "âœ“ Sentence Transformers imported successfully\n",
      "âœ“ Requests imported successfully\n",
      "\n",
      "âœ“ All dependencies imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test imports\n",
    "try:\n",
    "    import chromadb\n",
    "    print(\"âœ“ ChromaDB imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(\"âœ— ChromaDB import failed:\", e)\n",
    "    print(\"  Install with: pip install chromadb\")\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    print(\"âœ“ Sentence Transformers imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(\"âœ— Sentence Transformers import failed:\", e)\n",
    "    print(\"  Install with: pip install sentence-transformers\")\n",
    "\n",
    "try:\n",
    "    import requests\n",
    "    print(\"âœ“ Requests imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(\"âœ— Requests import failed:\", e)\n",
    "    print(\"  Install with: pip install requests\")\n",
    "\n",
    "print(\"\\nâœ“ All dependencies imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 2: Ollama LLM Connection\n",
    "\n",
    "This test checks if Ollama is running and accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Ollama is running and accessible\n",
      "\n",
      "Available models:\n",
      "  - mistral:7b\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "OLLAMA_URL = \"http://127.0.0.1:11434\"\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    response = requests.get(f\"{OLLAMA_URL}/api/tags\", timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(\"âœ“ Ollama is running and accessible\")\n",
    "        \n",
    "        # List available models\n",
    "        models = response.json().get('models', [])\n",
    "        if models:\n",
    "            print(f\"\\nAvailable models:\")\n",
    "            for model in models:\n",
    "                print(f\"  - {model['name']}\")\n",
    "        else:\n",
    "            print(\"\\nâš  No models found. You may need to pull a model.\")\n",
    "            print(\"  Run: docker exec ollama-mistral-offline ollama pull mistral\")\n",
    "    else:\n",
    "        print(f\"âœ— Ollama returned status code: {response.status_code}\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"âœ— Cannot connect to Ollama at\", OLLAMA_URL)\n",
    "    print(\"\\nMake sure:\")\n",
    "    print(\"  1. Docker Desktop is running\")\n",
    "    print(\"  2. Ollama container is started\")\n",
    "    print(\"  3. Check with: docker ps\")\n",
    "    print(\"\\nSee COMMANDS.txt for Docker setup instructions.\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 3: Embedding Model\n",
    "\n",
    "This test loads a small embedding model and creates a test embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "(This may take a minute on first run)\n",
      "\n",
      "âœ“ Embedding model loaded successfully\n",
      "\n",
      "Test embedding:\n",
      "  Text: 'Hello, this is a test sentence.'\n",
      "  Embedding dimension: 384\n",
      "  First 5 values: [ 0.0542045   0.09602845  0.02270416  0.10747132 -0.01486252]\n",
      "\n",
      "âœ“ Embedding model is working correctly!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"Loading embedding model...\")\n",
    "print(\"(This may take a minute on first run)\\n\")\n",
    "\n",
    "try:\n",
    "    # Load a small, fast model\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    print(\"âœ“ Embedding model loaded successfully\")\n",
    "    \n",
    "    # Test embedding\n",
    "    test_text = \"Hello, this is a test sentence.\"\n",
    "    embedding = model.encode(test_text)\n",
    "    \n",
    "    print(f\"\\nTest embedding:\")\n",
    "    print(f\"  Text: '{test_text}'\")\n",
    "    print(f\"  Embedding dimension: {len(embedding)}\")\n",
    "    print(f\"  First 5 values: {embedding[:5]}\")\n",
    "    print(\"\\nâœ“ Embedding model is working correctly!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error loading embedding model: {e}\")\n",
    "    print(\"\\nThis could mean:\")\n",
    "    print(\"  1. Not enough RAM (need at least 4GB free)\")\n",
    "    print(\"  2. No internet connection (needed for first download)\")\n",
    "    print(\"  3. Disk space issue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 4: ChromaDB Vector Database\n",
    "\n",
    "This test creates a temporary collection and tests basic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ChromaDB client initialized\n",
      "âœ“ Test collection created\n",
      "âœ“ Test documents added\n",
      "âœ“ Query executed successfully\n",
      "\n",
      "âœ“ ChromaDB is working correctly!\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Use a temporary directory for testing\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "try:\n",
    "    # Initialize ChromaDB\n",
    "    client = chromadb.PersistentClient(path=temp_dir)\n",
    "    print(\"âœ“ ChromaDB client initialized\")\n",
    "    \n",
    "    # Create a test collection\n",
    "    collection = client.create_collection(name=\"test_collection\")\n",
    "    print(\"âœ“ Test collection created\")\n",
    "    \n",
    "    # Add some test documents\n",
    "    collection.add(\n",
    "        documents=[\"This is document 1\", \"This is document 2\"],\n",
    "        ids=[\"doc1\", \"doc2\"]\n",
    "    )\n",
    "    print(\"âœ“ Test documents added\")\n",
    "    \n",
    "    # Query the collection\n",
    "    results = collection.query(\n",
    "        query_texts=[\"document\"],\n",
    "        n_results=2\n",
    "    )\n",
    "    print(\"âœ“ Query executed successfully\")\n",
    "    \n",
    "    # Clean up\n",
    "    client.delete_collection(name=\"test_collection\")\n",
    "    print(\"\\nâœ“ ChromaDB is working correctly!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— ChromaDB test failed: {e}\")\n",
    "finally:\n",
    "    # Clean up temp directory\n",
    "    import shutil\n",
    "    try:\n",
    "        shutil.rmtree(temp_dir)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 5: Basic LLM Interaction\n",
    "\n",
    "This test sends a simple prompt to the LLM and gets a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LLM with a simple question...\n",
      "(This may take 10-30 seconds)\n",
      "\n",
      "Prompt: Answer in one sentence: What is 2+2?\n",
      "Response:  The sum of 2 and 2 is 4.\n",
      "\n",
      "âœ“ LLM is responding correctly!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "OLLAMA_URL = \"http://127.0.0.1:11434\"\n",
    "MODEL_NAME = \"mistral:7b\"  # Change if using a different model\n",
    "\n",
    "def test_llm(prompt: str) -> str:\n",
    "    \"\"\"Send a prompt to Ollama and get response.\"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{OLLAMA_URL}/api/generate\",\n",
    "            json={\n",
    "                \"model\": MODEL_NAME,\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False\n",
    "            },\n",
    "            timeout=60\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()['response']\n",
    "        else:\n",
    "            return f\"Error: Status code {response.status_code}\"\n",
    "    \n",
    "    except requests.exceptions.ConnectionError:\n",
    "        return \"Error: Cannot connect to Ollama. Is the container running?\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Test the LLM\n",
    "print(\"Testing LLM with a simple question...\")\n",
    "print(\"(This may take 10-30 seconds)\\n\")\n",
    "\n",
    "test_prompt = \"Answer in one sentence: What is 2+2?\"\n",
    "response = test_llm(test_prompt)\n",
    "\n",
    "print(f\"Prompt: {test_prompt}\")\n",
    "print(f\"Response: {response}\")\n",
    "\n",
    "if \"Error\" not in response:\n",
    "    print(\"\\nâœ“ LLM is responding correctly!\")\n",
    "else:\n",
    "    print(\"\\nâœ— LLM test failed\")\n",
    "    print(\"\\nCheck:\")\n",
    "    print(\"  1. Ollama container is running: docker ps\")\n",
    "    print(\"  2. Correct model is installed\")\n",
    "    print(\"  3. See docker_commands.md for troubleshooting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ® Start playing with Chat Interface!\n",
    "\n",
    "Run this notebook after running your docker container!\n",
    "\n",
    "[Chat Interface](chat_interface.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 6: File System Access\n",
    "\n",
    "This test verifies you can read the sample documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ— Documents folder not found: ./docs/text\n",
      "  Make sure you're running this from the project root directory\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DOCS_FOLDER = \"./docs/text\"\n",
    "\n",
    "try:\n",
    "    docs_path = Path(DOCS_FOLDER)\n",
    "    \n",
    "    if not docs_path.exists():\n",
    "        print(f\"âœ— Documents folder not found: {DOCS_FOLDER}\")\n",
    "        print(\"  Make sure you're running this from the project root directory\")\n",
    "    else:\n",
    "        print(f\"âœ“ Documents folder found: {DOCS_FOLDER}\")\n",
    "        \n",
    "        # List text files\n",
    "        text_files = list(docs_path.glob(\"*.txt\"))\n",
    "        \n",
    "        if text_files:\n",
    "            print(f\"\\nâœ“ Found {len(text_files)} text file(s):\")\n",
    "            for file in text_files:\n",
    "                # Get file size\n",
    "                size = file.stat().st_size\n",
    "                print(f\"  - {file.name} ({size:,} bytes)\")\n",
    "            \n",
    "            # Test reading one file\n",
    "            test_file = text_files[0]\n",
    "            with open(test_file, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            print(f\"\\nâœ“ Successfully read {test_file.name}\")\n",
    "            print(f\"  Content preview: {content[:100]}...\")\n",
    "            print(\"\\nâœ“ File system access is working!\")\n",
    "        else:\n",
    "            print(f\"\\nâš  No .txt files found in {DOCS_FOLDER}\")\n",
    "            print(\"  You'll need documents to test your RAG system\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error accessing files: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "If all tests passed, your environment is ready!\n",
    "\n",
    "### Next Steps:\n",
    "1. Read `STUDENT_PROJECT_GUIDE.md` for assignment details\n",
    "2. Prepare your own document collection\n",
    "3. Start working on the TODO tasks\n",
    "\n",
    "### If Any Tests Failed:\n",
    "- Check the error messages above\n",
    "- See `docker_starter.md` for Docker setup\n",
    "- See `docker_comands.md` for Docker commands\n",
    "- Ask for help if you're stuck\n",
    "\n",
    "**Good luck with your project!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
